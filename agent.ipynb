{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b9a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antriksh Sharma\\AppData\\Local\\Temp\\ipykernel_18672\\2334523671.py:33: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=db_path, embedding_function=embedding_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTRIKSH SHARMA\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "import os, getpass\n",
    "\n",
    "# Load env vars\n",
    "load_dotenv()\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
    "\n",
    "# Step 1: Load PDF\n",
    "pdf_path = input(\"Enter PDF path: \")\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Also store raw text for LLM access\n",
    "raw_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Step 2: Split and Embed\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=30)\n",
    "docs_split = splitter.split_documents(docs)\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "# Persistent Chroma store\n",
    "db_path = \"./chroma_resume\"\n",
    "db = None\n",
    "if os.path.exists(db_path):\n",
    "    db = Chroma(persist_directory=db_path, embedding_function=embedding_model)\n",
    "else:\n",
    "    db = Chroma.from_documents(docs_split, embedding=embedding_model, persist_directory=db_path)\n",
    "    db.persist()\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Step 3: LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3)\n",
    "\n",
    "# Step 4: Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a resume parsing assistant. Use both the vector DB context and full raw PDF text to answer. \"\n",
    "     \"Match the resume data to produce a clean, structured output with sections:\\n\"\n",
    "     \"Keywords: Name, Contact, Skills, Education, Experience, Achievements, Certifications.\\n\"\n",
    "     \"Provide only mentioned keyword content in {input}, not all keywords content.\\n\\n\"\n",
    "     \"VectorDB Context:\\n{context}\\n\\nFull PDF Text:\\n{pdf_text}\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Step 5: Chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "resume_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"pdf_text\": lambda _: raw_text,\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "#C:/Users/Antriksh Sharma/Downloads/Antriksh Sharma (4).pdf\n",
    "# Step 6: Query\n",
    "query = \"hi give me name of resume holder\"\n",
    "response = resume_chain.invoke(query)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e96f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Chroma DB...\n",
      "\n",
      "ðŸ’¡ Response:\n",
      " The resume holder, Antriksh Sharma, is an Agentic AI Developer specializing in building intelligent automation systems and advanced machine learning solutions. They are proficient in developing end-to-end AI applications using Python, deep learning frameworks, and modern MLOps practices, with experience in implementing RAG systems, Langchain, and LangGraph workflows.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "import os, getpass, json\n",
    "\n",
    "CONFIG_FILE = \"resume_config.json\"\n",
    "DB_PATH = \"./chroma_resume\"\n",
    "\n",
    "# --- Load config if exists ---\n",
    "def load_config():\n",
    "    if os.path.exists(CONFIG_FILE):\n",
    "        with open(CONFIG_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_config(data):\n",
    "    with open(CONFIG_FILE, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "# --- Step 0: API Key ---\n",
    "load_dotenv()\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
    "\n",
    "# --- Step 1: Load or Ask for PDF ---\n",
    "config = load_config()\n",
    "pdf_path = config.get(\"pdf_path\")\n",
    "\n",
    "if not pdf_path or not os.path.exists(pdf_path):\n",
    "    pdf_path = input(\"Enter PDF path (upload your resume file): \").strip()\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
    "    save_config({\"pdf_path\": pdf_path})\n",
    "    print(f\"PDF path saved to {CONFIG_FILE}\")\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Store raw text for full PDF reference\n",
    "raw_text = \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# --- Step 2: Vector DB ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=30)\n",
    "docs_split = splitter.split_documents(docs)\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "if os.path.exists(DB_PATH) and os.listdir(DB_PATH):\n",
    "    print(\"Loading existing Chroma DB...\")\n",
    "    db = Chroma(persist_directory=DB_PATH, embedding_function=embedding_model)\n",
    "else:\n",
    "    print(\"Creating new Chroma DB...\")\n",
    "    db = Chroma.from_documents(docs_split, embedding=embedding_model, persist_directory=DB_PATH)\n",
    "    db.persist()\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# --- Step 3: LLM ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3)\n",
    "\n",
    "# --- Step 4: Prompt Template ---\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a resume parsing assistant. Use both the vector DB context and full raw PDF text to answer.\\n\"\n",
    "     \"Match the resume data to produce a clean, structured output with sections:\\n\"\n",
    "     \"Keywords: Name, Contact, Skills, Education, Experience, Achievements, Certifications.\\n\"\n",
    "     \"Provide only mentioned keyword content in {input}, not all keywords content.\\n\\n\"\n",
    "     \"VectorDB Context:\\n{context}\\n\\nFull PDF Text:\\n{pdf_text}\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# --- Step 5: Chain ---\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "resume_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"pdf_text\": lambda _: raw_text,\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# --- Step 6: Example Query ---\n",
    "query = \"hi give me summary of resume holder\"\n",
    "response = resume_chain.invoke(query)\n",
    "print(\"\\nðŸ’¡ Response:\\n\", response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
